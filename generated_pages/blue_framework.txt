TA1 Plan Strategy TA2 Plan Objectives TA5 Microtarget TA6 Develop Content TA7 Select Channels and Affordances TA8 Conduct Pump Priming TA9 Deliver Content TA10 Drive Offline Activity TA11 Persist in the Information Environment TA12 Assess Effectiveness TA13 Target Audience Analysis TA14 Develop Narratives TA15 Establish Assets TA16 Establish Legitimacy TA17 Maximise Exposure TA18 Drive Online Harms C06 Charge for social media C09 Educate high profile influencers on best practices C65 Reduce political targeting C14 Real-time updates to fact-checking database C90 Fake engagement system C100 Hashtag jacking C109 Dampen Emotional Reaction C131 Seize and analyse botnet servers C140 "Bomb" link shorteners with lots of calls C34 Create more friction at account creation C08 Create shared fact-checking database C11 Media literacy. Games to identify fake news C66 Co-opt hashtag and drown it out hijack it back C32 Hijack content and link to truth- based info C97 Require use of verified identities to contribute to poll or comment C112 "Prove they are not op!" C122 Content moderation C138 Spam domestic actors with lawsuits C148 Add random links to network graphs C36 Infiltrate the in-group to discredit leaders divide C10 Enhanced privacy regulation for social media C28 Make information provenance available C130 Mentorship: elders, youth, credit. Learn vicariously. C71 Block source of pollution C98 Revocation of allowlisted or "verified" status C113 Debunk and defuse fake expert/credentials. C123 Remove or rate limit botnets C139 Weaponise youtube content matrices C149 Poison the monitoring & evaluation data C40 third party verification for people C12 Platform regulation C29 Create fake website to issue counter narrative and counter narrative through physical merchandise C178 Fill information voids with non-disinformation content C72 Remove non-relevant content from special interest groups-not recommended C99 Strengthen verification methods C114 Don't engage with payloads C124 Don't feed the trolls C143 botnet DMCA takedown requests to waste group time C42 Address truth contained in narratives C13 Rating framework for news C30 Develop compelling counter narrative truth based C216 Use advertiser controls to stem flow of funds to bad actors C74 Identify and delete or rate limit identical content C101 Create friction by rate-limiting engagement C115 Expose actor and intentions C125 Prebunking C44 Keep people from posting to social media immediately C16 Censorship C31 Dilute the core narrative-create multiple permutations, target/amplify C75 normalise language C103 Create bot that engages/distract trolls C116 Provide proof of involvement C126 Social media amber alert C46 Marginalise and discredit extremist groups C17 Repair broken social connections C60 Legal action against for-profit engagement factories C76 Prohibit images in political discourse channels C105 Buy more advertising than misinformation creators C117 Downgrade/de-amplify so message is seen by fewer people C128 Create friction by marking content with ridicule or other "decelerants" C47 Honeypot with coordinated inauthentics C19 Reduce effect of division-enablers C70 Block access to disinformation resources C78 Change Search Algorithms for Disinformation Content C195 Redirect searches away from disinformation or extremist content C118 Repurpose images with new text C129 Use banking to cut off access C48 Name and Shame Influencers C21 Encourage in-person communication C92 Establish truth teller reputation score for influencers C80 Create competing narrative C119 Engage payload and debunk. C147 Make amplification of social media posts expire e.g. can't like/ retweet after n days C51 Counter social engineering training C22 Innoculate. Positive campaign to promote feeling of safety C144 Buy out troll farm employees/offer them jobs C81 Highlight flooding and noise, and explain motivations C120 Open dialogue about design of platforms to produce different outcomes C182 Redirection/malware detection/ remediation C52 Infiltrate platforms C24 Promote healthy narratives C156 Better tell your country or organisation story C82 Ground truthing as automated response to pollution C121 Tool transparency and literacy for channels people follow. C200 Respected figure influencer disavows misinfo C53 Delete old accounts/Remove unused social media accounts C26 Shore up democracy based messages C164 compatriot policy C84 Modify disinformation narratives, and rebroadcast them C136 Microtarget most likely targets then send them countermessages C211 Use humorous counter-narratives C56 Encourage people to leave social media C27 Create culture of civility C169 develop creative content hub C85 Mute content C154 Ask media not to report false information C58 Report crowdfunder as violator C73 Inoculate populations through media literacy training C207 Run competing disinformation campaign-not recommended C86 Distract from noise with addictive content C184 Media exposure C59 Verification of project before posting fund requests C96 Strengthen institutions that are always truth tellers C222 Tabletop simulations C87 Make more noise than the disinformation C188 Newsroom/Journalist training to counter influence moves C62 Free open library sources worldwide C111 Reduce polarisation by connecting and presenting sympathetic renditions of opposite views C91 Honeypot social community C67 Denigrate the recipient/ project of online funding C153 Take pre-emptive action against actors' infrastructure C94 Force full disclosure on corporate sponsor of research C77 Active defence: run TA15 "develop people”-not recommended C159 Have disinformation response plan C106 Click-bait centrist content C93 Influencer code of conduct C161 Coalition Building with stakeholders and Third-Party Inducements C107 Content moderation C133 Deplatform Account* C170 elevate information as critical domain of statecraft C142 Platform adds warning label and decision point when sharing content C135 Deplatform message groups and/or message boards C174 Create healthier news environment C165 Ensure integrity of official documents C155 Ban incident actors from funding sites C176 Improve Coordination amongst stakeholders: public and private C202 Set data 'honeytraps' C160 find and train influencers C190 open engagement with civil society C219 Add metadata to content that’s out of the control of disinformation creators C162 Unravel/target the Potemkin villages C205 strong dialogue between the federal government and private sector to encourage better reporting C172 social media source removal C212 build public resilience by making civil society more vibrant C189 Ensure that platforms are taking down flagged accounts C220 Develop monitoring and intelligence plan C197 remove suspicious accounts C221 Run disinformation red team, and design mitigation factors C203 Stop offering press credentials to propaganda outlets C223 Strengthen Trust in social media platforms TA1 Plan Strategy TA2 Plan Objectives TA5 Microtarget TA6 Develop Content TA7 Select Channels and Affordances TA8 Conduct Pump Priming TA9 Deliver Content TA10 Drive Offline Activity TA11 Persist in the Information Environment TA12 Assess Effectiveness TA13 Target Audience Analysis TA14 Develop Narratives TA15 Establish Assets TA16 Establish Legitimacy TA17 Maximise Exposure TA18 Drive Online Harms C06 Charge for social media C09 Educate high profile influencers on best practices C65 Reduce political targeting C14 Real-time updates to fact-checking database C90 Fake engagement system C100 Hashtag jacking C109 Dampen Emotional Reaction C131 Seize and analyse botnet servers C140 "Bomb" link shorteners with lots of calls C34 Create more friction at account creation C08 Create shared fact-checking database C11 Media literacy. Games to identify fake news C66 Co-opt hashtag and drown it out hijack it back C32 Hijack content and link to truth- based info C97 Require use of verified identities to contribute to poll or comment C112 "Prove they are not op!" C122 Content moderation C138 Spam domestic actors with lawsuits C148 Add random links to network graphs C36 Infiltrate the in-group to discredit leaders divide C10 Enhanced privacy regulation for social media C28 Make information provenance available C130 Mentorship: elders, youth, credit. Learn vicariously. C71 Block source of pollution C98 Revocation of allowlisted or "verified" status C113 Debunk and defuse fake expert/credentials. C123 Remove or rate limit botnets C139 Weaponise youtube content matrices C149 Poison the monitoring & evaluation data C40 third party verification for people C12 Platform regulation C29 Create fake website to issue counter narrative and counter narrative through physical merchandise C178 Fill information voids with non-disinformation content C72 Remove non-relevant content from special interest groups-not recommended C99 Strengthen verification methods C114 Don't engage with payloads C124 Don't feed the trolls C143 botnet DMCA takedown requests to waste group time C42 Address truth contained in narratives C13 Rating framework for news C30 Develop compelling counter narrative truth based C216 Use advertiser controls to stem flow of funds to bad actors C74 Identify and delete or rate limit identical content C101 Create friction by rate-limiting engagement C115 Expose actor and intentions C125 Prebunking C44 Keep people from posting to social media immediately C16 Censorship C31 Dilute the core narrative-create multiple permutations, target/amplify C75 normalise language C103 Create bot that engages/distract trolls C116 Provide proof of involvement C126 Social media amber alert C46 Marginalise and discredit extremist groups C17 Repair broken social connections C60 Legal action against for-profit engagement factories C76 Prohibit images in political discourse channels C105 Buy more advertising than misinformation creators C117 Downgrade/de-amplify so message is seen by fewer people C128 Create friction by marking content with ridicule or other "decelerants" C47 Honeypot with coordinated inauthentics C19 Reduce effect of division-enablers C70 Block access to disinformation resources C78 Change Search Algorithms for Disinformation Content C195 Redirect searches away from disinformation or extremist content C118 Repurpose images with new text C129 Use banking to cut off access C48 Name and Shame Influencers C21 Encourage in-person communication C92 Establish truth teller reputation score for influencers C80 Create competing narrative C119 Engage payload and debunk. C147 Make amplification of social media posts expire e.g. can't like/ retweet after n days C51 Counter social engineering training C22 Innoculate. Positive campaign to promote feeling of safety C144 Buy out troll farm employees/offer them jobs C81 Highlight flooding and noise, and explain motivations C120 Open dialogue about design of platforms to produce different outcomes C182 Redirection/malware detection/ remediation C52 Infiltrate platforms C24 Promote healthy narratives C156 Better tell your country or organisation story C82 Ground truthing as automated response to pollution C121 Tool transparency and literacy for channels people follow. C200 Respected figure influencer disavows misinfo C53 Delete old accounts/Remove unused social media accounts C26 Shore up democracy based messages C164 compatriot policy C84 Modify disinformation narratives, and rebroadcast them C136 Microtarget most likely targets then send them countermessages C211 Use humorous counter-narratives C56 Encourage people to leave social media C27 Create culture of civility C169 develop creative content hub C85 Mute content C154 Ask media not to report false information C58 Report crowdfunder as violator C73 Inoculate populations through media literacy training C207 Run competing disinformation campaign-not recommended C86 Distract from noise with addictive content C184 Media exposure C59 Verification of project before posting fund requests C96 Strengthen institutions that are always truth tellers C222 Tabletop simulations C87 Make more noise than the disinformation C188 Newsroom/Journalist training to counter influence moves C62 Free open library sources worldwide C111 Reduce polarisation by connecting and presenting sympathetic renditions of opposite views C91 Honeypot social community C67 Denigrate the recipient/ project of online funding C153 Take pre-emptive action against actors' infrastructure C94 Force full disclosure on corporate sponsor of research C77 Active defence: run TA15 "develop people”-not recommended C159 Have disinformation response plan C106 Click-bait centrist content C93 Influencer code of conduct C161 Coalition Building with stakeholders and Third-Party Inducements C107 Content moderation C133 Deplatform Account* C170 elevate information as critical domain of statecraft C142 Platform adds warning label and decision point when sharing content C135 Deplatform message groups and/or message boards C174 Create healthier news environment C165 Ensure integrity of official documents C155 Ban incident actors from funding sites C176 Improve Coordination amongst stakeholders: public and private C202 Set data 'honeytraps' C160 find and train influencers C190 open engagement with civil society C219 Add metadata to content that’s out of the control of disinformation creators C162 Unravel/target the Potemkin villages C205 strong dialogue between the federal government and private sector to encourage better reporting C172 social media source removal C212 build public resilience by making civil society more vibrant C189 Ensure that platforms are taking down flagged accounts C220 Develop monitoring and intelligence plan C197 remove suspicious accounts C221 Run disinformation red team, and design mitigation factors C203 Stop offering press credentials to propaganda outlets C223 Strengthen Trust in social media platforms